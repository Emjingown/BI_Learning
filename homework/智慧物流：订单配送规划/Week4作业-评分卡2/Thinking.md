* **Thinking1：逻辑回归的假设条件是怎样的？**

  * 数据服从伯努利分布

  * 正类的概率由sigmoid函数计算

    

* **Thinking2：逻辑回归的损失函数是怎样的？**
  $$
  J(\theta) = -\frac{1}{m}\sum_{i=1}^{m}(y^{(i)}\log h_\theta (x^{(i)}) + (1-y^{(i)})\log (1-h_\theta (x^{(i)})))
  $$
  

* **Thinking3：逻辑回归如何进行分类？**

  * 设定一个阈值，判断正类概率是否大于该阈值
  * 一般阈值是0.5，所以只用判断正类概率是否大于0.5即可

  

* **Thinking4：为什么在训练中需要将高度相关的特征去掉？**

  * 去除多重共线性，可解释性更好
  * 提高模型训练速度

