{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先进行中文分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import os\n",
    "from utils import files_processing\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--', '?', '“', '”', '》']\n"
     ]
    }
   ],
   "source": [
    "with open('百度停用词表.txt', 'r') as f:\n",
    "    stopwords = f.read().split('\\n')\n",
    "print(stopwords[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分词完成，保存为文件segment_0.txt.\n"
     ]
    }
   ],
   "source": [
    "# 源文件所在目录\n",
    "source_folder = './source'\n",
    "segment_folder = './segment'\n",
    "\n",
    "# 字词分割，对整个文件内容进行字词分割\n",
    "def segment_lines(file_list,segment_out_dir,stopwords=[]):\n",
    "    for i,file in enumerate(file_list):\n",
    "        segment_out_name=os.path.join(segment_out_dir,'segment_{}.txt'.format(i))\n",
    "        with open(file, 'rb') as f:\n",
    "            document = f.read()\n",
    "            document_cut = jieba.cut(document)\n",
    "            sentence_segment=[]\n",
    "            for word in document_cut:\n",
    "                if word not in stopwords:\n",
    "                    sentence_segment.append(word)\n",
    "            result = ' '.join(sentence_segment)\n",
    "            result = result.encode('utf-8')\n",
    "            with open(segment_out_name, 'wb') as f2:\n",
    "                f2.write(result)\n",
    "                print(f\"分词完成，保存为文件{'segment_{}.txt'.format(i)}.\")\n",
    "\n",
    "# 对source中的txt文件进行分词，输出到segment目录中\n",
    "file_list=files_processing.get_files_list(source_folder, postfix='*.txt')\n",
    "\n",
    "# 不使用停用词\n",
    "segment_lines(file_list, segment_folder)\n",
    "\n",
    "# 使用停用词（使用停用词后结果好像更差）\n",
    "# segment_lines(file_list, segment_folder, stopwords=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding与相似度计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import multiprocessing\n",
    "\n",
    "# 如果目录中有多个文件，可以使用PathLineSentences\n",
    "segment_folder = './segment'\n",
    "sentences = word2vec.PathLineSentences(segment_folder)\n",
    "\n",
    "# 设置模型参数，进行训练\n",
    "model = word2vec.Word2Vec(sentences, size=100, window=3, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到与曹操最相近的10个词以及对应相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['夫人', '关公', '孔明', '众将', '先主', '此事', '孙权', '后主', '韩福', '糜夫人']\n"
     ]
    }
   ],
   "source": [
    "print([t[0] for t in model.wv.most_similar(positive='曹操', topn=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 曹操+刘备-张飞=?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('某', 0.9953306317329407)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['曹操', '刘备'], negative=['张飞'], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上述结果来看，模型效果不太好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数调整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 参数size：词向量的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size = 25:\n",
      "['孔明', '关公', '门吏', '先主', '大哭', '孙权', '又', '瑁', '众将', '司马懿']\n",
      "[('丞相', 0.9954825043678284), ('朕', 0.9948809742927551), ('某', 0.9944384098052979)]\n",
      "\n",
      "size = 50:\n",
      "['先主', '关公', '进', '孔明', '孙权', '已', '司马懿', '老人', '吴押狱', '门吏']\n",
      "[('谏', 0.9943273663520813), ('朕', 0.9935682415962219), ('大叫', 0.992993950843811)]\n",
      "\n",
      "size = 75:\n",
      "['关公', '孔明', '先主', '夫人', '孙权', '超', '众将', '泣', '司马懿', '孔明问']\n",
      "[('主母', 0.9921486377716064), ('某', 0.9909951090812683), ('土人', 0.9903910160064697)]\n",
      "\n",
      "size = 100:\n",
      "['众将', '关公', '孔明', '司马懿', '惇', '请', '渊', '夫人', '大惊', '庞统']\n",
      "[('臣', 0.9968320727348328), ('主公', 0.9955992698669434), ('丞相', 0.994544267654419)]\n",
      "\n",
      "size = 125:\n",
      "['关公', '孔明', '先主', '孙权', '禁', '回报', '逊谢', '实情', '生平', '云长']\n",
      "[('泣', 0.9940541982650757), ('今', 0.9935337901115417), ('臣', 0.9933633804321289)]\n",
      "\n",
      "size = 150:\n",
      "['孙权', '后患', '关公', '辞回', '周瑜', '下令', '回报', '已', '夫人', '又']\n",
      "[('杨松', 0.996979296207428), ('诸葛丞相', 0.9958659410476685), ('欲行', 0.994485080242157)]\n",
      "\n",
      "size = 175:\n",
      "['孔明', '孙权', '大惊', '老人', '他', '二人', '重用', '枭雄', '关公', '细言']\n",
      "[('谕', 0.9959574341773987), ('主公', 0.9954847097396851), ('泣', 0.9952856302261353)]\n",
      "\n",
      "size = 200:\n",
      "['众官', '义渠', '糜夫人', '众将', '周瑜', '相会', '司马懿', '俭', '深恨', '大惊']\n",
      "[('主公', 0.9962875247001648), ('嘱', 0.9955697059631348), ('孔明问', 0.9947665333747864)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in range(25, 201, 25):\n",
    "    print(f\"size = {s}:\")\n",
    "    model = word2vec.Word2Vec(sentences, size=s, window=3, min_count=1, seed=0)\n",
    "    print([t[0] for t in model.wv.most_similar(positive='曹操', topn=10)])\n",
    "    print(model.wv.most_similar(positive=['曹操', '刘备'], negative=['张飞'], topn=3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### window：Maximum distance between the current and predicted word within a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window = 1:\n",
      "['孔明', '张飞', '周瑜', '赵云', '孙权', '姜维', '吕布', '关公', '马超', '袁绍']\n",
      "[('袁绍', 0.9919048547744751), ('周瑜', 0.9916937351226807), ('将军', 0.9872189164161682)]\n",
      "\n",
      "window = 2:\n",
      "['司马懿', '孔明', '周瑜', '孙权', '张飞', '关公', '夫人', '他', '众官', '大惊']\n",
      "[('臣', 0.9932695627212524), ('今日', 0.9928516149520874), ('扬鞭', 0.9925713539123535)]\n",
      "\n",
      "window = 3:\n",
      "['众官', '孔明', '以破', '大惊', '张飞', '孙权', '超大', '相探', '王植', '二人']\n",
      "[('先生', 0.9947894811630249), ('丞相', 0.994509220123291), ('之言', 0.9938519597053528)]\n",
      "\n",
      "window = 4:\n",
      "['孔明', '岱', '重用', '众将', '荆州', '邀', '关公', '先主', '孙权', '擅离']\n",
      "[('祎', 0.9960540533065796), ('朕', 0.99573814868927), ('攸', 0.9955790042877197)]\n",
      "\n",
      "window = 5:\n",
      "['孔明问', '已', '那里', '孔明', '就此', '关公', '众', '下手', '众将', '策怒']\n",
      "[('此', 0.997637927532196), ('大笑', 0.9973338842391968), ('如此', 0.996761679649353)]\n",
      "\n",
      "window = 6:\n",
      "['那里', '已', '誓同生死', '关公', '玄德再', '细奏', '超', '传令', '计策', '起身']\n",
      "[('问', 0.9963052272796631), ('公言', 0.995137631893158), ('仰天', 0.9950897097587585)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w in range(1, 7):\n",
    "    print(f\"window = {w}:\")\n",
    "    model = word2vec.Word2Vec(sentences, size=125, window=w, min_count=1, seed=0)\n",
    "    print([t[0] for t in model.wv.most_similar(positive='曹操', topn=10)])\n",
    "    print(model.wv.most_similar(positive=['曹操', '刘备'], negative=['张飞'], topn=3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_count：Ignores all words with total frequency lower than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_count = 1:\n",
      "['孔明', '张飞', '赵云', '孙权', '周瑜', '姜维', '关公', '吕布', '孟获', '马超']\n",
      "[('袁绍', 0.992116391658783), ('周瑜', 0.9916278123855591), ('陈宫', 0.9881535172462463)]\n",
      "\n",
      "min_count = 2:\n",
      "['孔明', '张飞', '赵云', '玄德', '姜维', '吕布', '周瑜', '魏延', '关公', '孙权']\n",
      "[('将军', 0.9678764343261719), ('袁绍', 0.9662936329841614), ('臣', 0.9654808640480042)]\n",
      "\n",
      "min_count = 3:\n",
      "['孔明', '张飞', '赵云', '马超', '孙权', '孟获', '关公', '周瑜', '吕布', '姜维']\n",
      "[('此间', 0.9758447408676147), ('此', 0.9707177877426147), ('丞相', 0.9685412645339966)]\n",
      "\n",
      "min_count = 4:\n",
      "['孔明', '张飞', '赵云', '吕布', '周瑜', '关公', '孟获', '姜维', '马超', '魏延']\n",
      "[('汝二人', 0.9631171822547913), ('司马懿', 0.9602318406105042), ('某愿', 0.955371618270874)]\n",
      "\n",
      "min_count = 5:\n",
      "['周瑜', '张飞', '吕布', '孔明', '赵云', '孙权', '马超', '关公', '孟获', '袁绍']\n",
      "[('卿', 0.9624482989311218), ('此', 0.9620213508605957), ('但', 0.9618009328842163)]\n",
      "\n",
      "min_count = 6:\n",
      "['吕布', '周瑜', '赵云', '马超', '孙权', '张飞', '孔明', '袁绍', '孟获', '司马懿']\n",
      "[('卿', 0.9499633312225342), ('起谢', 0.9448398351669312), ('此', 0.9405841827392578)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mc in range(1, 7):\n",
    "    print(f\"min_count = {mc}:\")\n",
    "    model = word2vec.Word2Vec(sentences, size=125, window=1, min_count=mc, seed=0)\n",
    "    print([t[0] for t in model.wv.most_similar(positive='曹操', topn=10)])\n",
    "    print(model.wv.most_similar(positive=['曹操', '刘备'], negative=['张飞'], topn=3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最后选择参数组为：size=125, window=1, min_count=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['孔明', '张飞', '吕布', '玄德', '姜维', '赵云', '周瑜', '魏延', '关公', '孙权']\n",
      "[('将军', 0.9688045978546143), ('陈宫', 0.9681386351585388), ('袁绍', 0.9658312797546387)]\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences, size=125, window=1, min_count=2, seed=0)\n",
    "print([t[0] for t in model.wv.most_similar(positive='曹操', topn=10)])\n",
    "print(model.wv.most_similar(positive=['曹操', '刘备'], negative=['张飞'], topn=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
